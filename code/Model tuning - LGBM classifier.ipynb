{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning : LightGBM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan :**\n",
    "\n",
    "[1. Loading the libraries and the data](#1)  \n",
    "[2. Tuning the parameters](#2)  \n",
    "> [Max depth tuning](#2a)  \n",
    "> [Number of leaves tuning](#2b)  \n",
    "> [Min data in leaves tuning](#2c)  \n",
    "> [Lasso regularization tuning](#2d)   \n",
    "> [Ridge regularization tuning](#2e)   \n",
    "> [Max bins tuning](#2f)   \n",
    "> [Feature fraction tuning](#2g) \n",
    "\n",
    "[3. Defining the best parameters](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Loading the libraries and the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import igraph\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the features created in the feature engineering code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_complete.csv', header = 0)\n",
    "test = pd.read_csv('test_complete.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Title overlap', 'Abstract overlap', 'Temporal difference', 'Common authors', 'Common journal',\n",
    "            'Cosine similarity', 'Authors in abstract', 'LSA distance', # Semantic features\n",
    "            'Betweenness centrality', 'Same cluster', 'Page rank', 'Ressource allocation', 'Jaccard coefficient',\n",
    "            'Adamic Adar', 'Preferential attachment', 'Target_indegree', 'Target_outdegree',\n",
    "            'Source_indegree', 'Source_outdegree', 'Common_in', 'Common_out' #Topological features\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = train[features]\n",
    "testing_features = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = train['Edge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Overlap abstract</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>res_alloc</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>ad_adar</th>\n",
       "      <th>...</th>\n",
       "      <th>Common_out</th>\n",
       "      <th>Transitive_ts</th>\n",
       "      <th>Transitive_st</th>\n",
       "      <th>Friend_measure_st</th>\n",
       "      <th>Friend_measure_ts</th>\n",
       "      <th>Scc</th>\n",
       "      <th>Wcc</th>\n",
       "      <th>Scc_plus</th>\n",
       "      <th>Len_path_st</th>\n",
       "      <th>Len_path_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226401</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>4.320366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title overlap  Temporal difference  Common authors  Cosine similarity  \\\n",
       "0            2.0                  0.0             0.0           0.039132   \n",
       "1            1.0                  1.0             0.0           0.015247   \n",
       "2            0.0                 -2.0             0.0           0.008888   \n",
       "3            0.0                 -4.0             0.0           0.004740   \n",
       "4            0.0                 -5.0             0.0           0.027379   \n",
       "\n",
       "   Common journal  Overlap abstract  Authors in abstract  res_alloc   Jaccard  \\\n",
       "0             1.0               4.0                  0.0   0.142857  0.058824   \n",
       "1             0.0               7.0                  0.0   0.226401  0.097087   \n",
       "2             0.0               6.0                  0.0   0.000000  0.000000   \n",
       "3             0.0               8.0                  0.0   0.000000  0.000000   \n",
       "4             0.0               8.0                  0.0   0.000000  0.000000   \n",
       "\n",
       "    ad_adar     ...       Common_out  Transitive_ts  Transitive_st  \\\n",
       "0  0.513898     ...              0.0            0.0            0.0   \n",
       "1  4.320366     ...              0.0            0.0            0.0   \n",
       "2  0.000000     ...              0.0            0.0            0.0   \n",
       "3  0.000000     ...              0.0            0.0            0.0   \n",
       "4  0.000000     ...              0.0            0.0            0.0   \n",
       "\n",
       "   Friend_measure_st  Friend_measure_ts    Scc   Wcc  Scc_plus  Len_path_st  \\\n",
       "0                0.0                0.0   14.0  12.0      16.0         -1.0   \n",
       "1              576.0              181.0  161.0   1.0     163.0         -1.0   \n",
       "2                0.0                0.0    4.0   4.0       6.0         -1.0   \n",
       "3               14.0                0.0   27.0   1.0      29.0          6.0   \n",
       "4                1.0                0.0   23.0   2.0      25.0          3.0   \n",
       "\n",
       "   Len_path_ts  \n",
       "0         -1.0  \n",
       "1          2.0  \n",
       "2         -1.0  \n",
       "3         -1.0  \n",
       "4         -1.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Overlap abstract</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>res_alloc</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>ad_adar</th>\n",
       "      <th>...</th>\n",
       "      <th>Common_out</th>\n",
       "      <th>Transitive_ts</th>\n",
       "      <th>Transitive_st</th>\n",
       "      <th>Friend_measure_st</th>\n",
       "      <th>Friend_measure_ts</th>\n",
       "      <th>Scc</th>\n",
       "      <th>Wcc</th>\n",
       "      <th>Scc_plus</th>\n",
       "      <th>Len_path_st</th>\n",
       "      <th>Len_path_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311535</td>\n",
       "      <td>0.074303</td>\n",
       "      <td>5.377973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342594</td>\n",
       "      <td>0.065338</td>\n",
       "      <td>15.053612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298419</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>4.899424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title overlap  Temporal difference  Common authors  Cosine similarity  \\\n",
       "0            0.0                  0.0             0.0           0.055452   \n",
       "1            2.0                  1.0             0.0           0.110670   \n",
       "2            1.0                  2.0             0.0           0.043831   \n",
       "3            1.0                  0.0             0.0           0.054856   \n",
       "4            0.0                  5.0             0.0           0.147222   \n",
       "\n",
       "   Common journal  Overlap abstract  Authors in abstract  res_alloc   Jaccard  \\\n",
       "0             0.0               7.0                  0.0   0.000000  0.000000   \n",
       "1             1.0               6.0                  0.0   0.311535  0.074303   \n",
       "2             1.0               4.0                  0.0   1.342594  0.065338   \n",
       "3             1.0              13.0                  0.0   0.298419  0.221053   \n",
       "4             0.0               4.0                  0.0   0.000000  0.000000   \n",
       "\n",
       "     ad_adar     ...       Common_out  Transitive_ts  Transitive_st  \\\n",
       "0   0.000000     ...              0.0            0.0            0.0   \n",
       "1   5.377973     ...              0.0            0.0            0.0   \n",
       "2  15.053612     ...              0.0            0.0            0.0   \n",
       "3   4.899424     ...              0.0            0.0            0.0   \n",
       "4   0.000000     ...              0.0            0.0            0.0   \n",
       "\n",
       "   Friend_measure_st  Friend_measure_ts    Scc  Wcc  Scc_plus  Len_path_st  \\\n",
       "0                0.0                2.0   77.0  1.0      79.0          7.0   \n",
       "1              864.0              910.0  302.0  6.0     302.0         13.0   \n",
       "2             1924.0             2080.0  901.0  4.0     903.0         -1.0   \n",
       "3              399.0              385.0   95.0  1.0      97.0          9.0   \n",
       "4                8.0                7.0  156.0  9.0     158.0         -1.0   \n",
       "\n",
       "   Len_path_ts  \n",
       "0         16.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          3.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print training_features.shape\n",
    "print testing_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/delavergne/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/delavergne/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "with open(\"data/testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]\n",
    "\n",
    "###################\n",
    "# random baseline #\n",
    "###################\n",
    "\n",
    "random_predictions = np.random.choice([0, 1], size=len(testing_set))\n",
    "random_predictions = zip(range(len(testing_set)),random_predictions)\n",
    "\n",
    "with open(\"data/random_predictions.csv\",\"wb\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    for row in random_predictions:\n",
    "        csv_out.writerow(row)\n",
    "        \n",
    "# note: Kaggle requires that you add \"ID\" and \"category\" column headers\n",
    "\n",
    "###############################\n",
    "# beating the random baseline #\n",
    "###############################\n",
    "\n",
    "# the following script gets an F1 score of approximately 0.66\n",
    "\n",
    "# data loading and preprocessing \n",
    "\n",
    "# the columns of the data frame below are: \n",
    "# (1) paper unique ID (integer)\n",
    "# (2) publication year (integer)\n",
    "# (3) paper title (string)\n",
    "# (4) authors (strings separated by ,)\n",
    "# (5) name of journal (optional) (string)\n",
    "# (6) abstract (string) - lowercased, free of punctuation except intra-word dashes\n",
    "\n",
    "with open(\"data/training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "\n",
    "with open(\"data/node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Tuning the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "training_features = min_max_scaler.fit_transform(training_features)\n",
    "testing_features = min_max_scaler.transform(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid, y_train, y_valid,  = train_test_split(training_features, labels_array, test_size = 0.4) # with your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246205,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_score_lgbm(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    tp = np.sum(labels[labels == 1] == (preds[labels == 1] > 0.5))\n",
    "    tn = np.sum(labels[labels == 0] == (preds[labels == 0] > 0.5))\n",
    "    fp = np.sum(labels[labels == 1] != (preds[labels == 1] > 0.5))\n",
    "    fn = np.sum(labels[labels == 0] != (preds[labels == 0] > 0.5))\n",
    "    p = tp / float(tp + fp)\n",
    "    r = tp / float(tp + fn)\n",
    "\n",
    "    return 'f1 score', (2 * p * r / (p + r)), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary'}\n",
    "# form LightGBM datasets\n",
    "dtrain_lgb = lgb.Dataset(train, y_train)\n",
    "deval_lgb = lgb.Dataset(valid, y_valid, reference=dtrain_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2a\"></a>\n",
    "### Max depth tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 64\n",
      "[50]\tcv_agg's binary_logloss: 0.0795454 + 0.000979466\n",
      "[100]\tcv_agg's binary_logloss: 0.0641691 + 0.00117504\n",
      "[150]\tcv_agg's binary_logloss: 0.0615719 + 0.00116461\n",
      "[200]\tcv_agg's binary_logloss: 0.0641916 + 0.00250378\n",
      "Starting cv for : 32\n",
      "[50]\tcv_agg's binary_logloss: 0.0795454 + 0.000979466\n",
      "[100]\tcv_agg's binary_logloss: 0.0641691 + 0.00117504\n",
      "[150]\tcv_agg's binary_logloss: 0.0615719 + 0.00116461\n",
      "[200]\tcv_agg's binary_logloss: 0.0641916 + 0.00250378\n",
      "Starting cv for : 16\n",
      "[50]\tcv_agg's binary_logloss: 0.0795454 + 0.000979466\n",
      "[100]\tcv_agg's binary_logloss: 0.064213 + 0.00118243\n",
      "[150]\tcv_agg's binary_logloss: 0.0615643 + 0.00127109\n",
      "[200]\tcv_agg's binary_logloss: 0.0625555 + 0.000981934\n",
      "Starting cv for : 8\n",
      "[50]\tcv_agg's binary_logloss: 0.0796872 + 0.00100198\n",
      "[100]\tcv_agg's binary_logloss: 0.0646964 + 0.00119372\n",
      "[150]\tcv_agg's binary_logloss: 0.0618836 + 0.00117435\n",
      "[200]\tcv_agg's binary_logloss: 0.0614443 + 0.00163817\n",
      "Starting cv for : 4\n",
      "[50]\tcv_agg's binary_logloss: 0.0871718 + 0.000924393\n",
      "[100]\tcv_agg's binary_logloss: 0.0691146 + 0.00111743\n",
      "[150]\tcv_agg's binary_logloss: 0.0652982 + 0.00117947\n",
      "[200]\tcv_agg's binary_logloss: 0.063351 + 0.00125922\n",
      "[250]\tcv_agg's binary_logloss: 0.06209 + 0.00132284\n",
      "[300]\tcv_agg's binary_logloss: 0.0611852 + 0.00128709\n",
      "[350]\tcv_agg's binary_logloss: 0.0605569 + 0.00126531\n",
      "[400]\tcv_agg's binary_logloss: 0.0601424 + 0.00129053\n",
      "[450]\tcv_agg's binary_logloss: 0.0599214 + 0.00139953\n",
      "[500]\tcv_agg's binary_logloss: 0.0609497 + 0.00368726\n",
      "[550]\tcv_agg's binary_logloss: 0.0594651 + 0.00153832\n",
      "[600]\tcv_agg's binary_logloss: 0.0592846 + 0.00156972\n",
      "[650]\tcv_agg's binary_logloss: 0.0591398 + 0.00159503\n",
      "[700]\tcv_agg's binary_logloss: 0.059179 + 0.0014697\n",
      "Starting cv for : 2\n",
      "[50]\tcv_agg's binary_logloss: 0.101599 + 0.00102614\n",
      "[100]\tcv_agg's binary_logloss: 0.0796225 + 0.0010104\n",
      "[150]\tcv_agg's binary_logloss: 0.0733757 + 0.00111329\n",
      "[200]\tcv_agg's binary_logloss: 0.0703323 + 0.00119231\n",
      "[250]\tcv_agg's binary_logloss: 0.068589 + 0.00122086\n",
      "[300]\tcv_agg's binary_logloss: 0.0673674 + 0.00127506\n",
      "[350]\tcv_agg's binary_logloss: 0.0663054 + 0.00127833\n",
      "[400]\tcv_agg's binary_logloss: 0.0655157 + 0.00131115\n",
      "[450]\tcv_agg's binary_logloss: 0.0648534 + 0.00131761\n",
      "[500]\tcv_agg's binary_logloss: 0.0642949 + 0.00133376\n",
      "[550]\tcv_agg's binary_logloss: 0.0638257 + 0.00131668\n",
      "[600]\tcv_agg's binary_logloss: 0.0633865 + 0.00132738\n",
      "[650]\tcv_agg's binary_logloss: 0.0630213 + 0.00133769\n",
      "[700]\tcv_agg's binary_logloss: 0.0627148 + 0.00133938\n",
      "[750]\tcv_agg's binary_logloss: 0.0624394 + 0.00134562\n",
      "[800]\tcv_agg's binary_logloss: 0.0621774 + 0.00135275\n",
      "[850]\tcv_agg's binary_logloss: 0.0619579 + 0.00135176\n",
      "[900]\tcv_agg's binary_logloss: 0.061752 + 0.00134974\n",
      "[950]\tcv_agg's binary_logloss: 0.0615481 + 0.00135214\n",
      "[1000]\tcv_agg's binary_logloss: 0.0613689 + 0.0013561\n",
      "[1050]\tcv_agg's binary_logloss: 0.0612073 + 0.00135204\n",
      "[1100]\tcv_agg's binary_logloss: 0.0610524 + 0.00135271\n",
      "[1150]\tcv_agg's binary_logloss: 0.0609107 + 0.00136403\n",
      "[1200]\tcv_agg's binary_logloss: 0.0607777 + 0.0013676\n",
      "[1250]\tcv_agg's binary_logloss: 0.0606549 + 0.00136215\n",
      "[1300]\tcv_agg's binary_logloss: 0.0605362 + 0.00136881\n",
      "[1350]\tcv_agg's binary_logloss: 0.0604267 + 0.00136854\n",
      "[1400]\tcv_agg's binary_logloss: 0.0603246 + 0.00136928\n",
      "[1450]\tcv_agg's binary_logloss: 0.0602362 + 0.00135972\n",
      "[1500]\tcv_agg's binary_logloss: 0.0601443 + 0.00135637\n",
      "[1550]\tcv_agg's binary_logloss: 0.0600524 + 0.00135022\n",
      "[1600]\tcv_agg's binary_logloss: 0.0599687 + 0.00135495\n",
      "[1650]\tcv_agg's binary_logloss: 0.0598939 + 0.00135446\n",
      "[1700]\tcv_agg's binary_logloss: 0.0598242 + 0.00135381\n",
      "[1750]\tcv_agg's binary_logloss: 0.0597535 + 0.00135115\n",
      "[1800]\tcv_agg's binary_logloss: 0.0596963 + 0.00135168\n",
      "[1850]\tcv_agg's binary_logloss: 0.0596354 + 0.00135038\n",
      "[1900]\tcv_agg's binary_logloss: 0.059581 + 0.00134758\n",
      "[1950]\tcv_agg's binary_logloss: 0.0595221 + 0.00134618\n",
      "[2000]\tcv_agg's binary_logloss: 0.0594707 + 0.00135553\n",
      "[2050]\tcv_agg's binary_logloss: 0.0594214 + 0.00134986\n",
      "[2100]\tcv_agg's binary_logloss: 0.0593671 + 0.00135047\n",
      "[2150]\tcv_agg's binary_logloss: 0.0593218 + 0.0013537\n",
      "[2200]\tcv_agg's binary_logloss: 0.0592791 + 0.00135584\n",
      "[2250]\tcv_agg's binary_logloss: 0.0592442 + 0.0013551\n",
      "[2300]\tcv_agg's binary_logloss: 0.0592039 + 0.00135387\n",
      "[2350]\tcv_agg's binary_logloss: 0.059165 + 0.00135723\n",
      "[2400]\tcv_agg's binary_logloss: 0.0591341 + 0.00136281\n",
      "[2450]\tcv_agg's binary_logloss: 0.0590989 + 0.00136562\n",
      "[2500]\tcv_agg's binary_logloss: 0.0590668 + 0.0013674\n",
      "[2550]\tcv_agg's binary_logloss: 0.0590333 + 0.0013718\n",
      "[2600]\tcv_agg's binary_logloss: 0.0590039 + 0.00137554\n",
      "[2650]\tcv_agg's binary_logloss: 0.0589764 + 0.00137393\n",
      "[2700]\tcv_agg's binary_logloss: 0.0589442 + 0.00137668\n",
      "[2750]\tcv_agg's binary_logloss: 0.058914 + 0.00137105\n",
      "[2800]\tcv_agg's binary_logloss: 0.0588891 + 0.00136896\n",
      "[2850]\tcv_agg's binary_logloss: 0.0588587 + 0.001371\n",
      "[2900]\tcv_agg's binary_logloss: 0.0588389 + 0.0013687\n",
      "[2950]\tcv_agg's binary_logloss: 0.0588183 + 0.00136834\n",
      "[3000]\tcv_agg's binary_logloss: 0.0588 + 0.0013633\n",
      "[3050]\tcv_agg's binary_logloss: 0.0587786 + 0.00137006\n",
      "[3100]\tcv_agg's binary_logloss: 0.0587559 + 0.00136898\n",
      "[3150]\tcv_agg's binary_logloss: 0.058737 + 0.00137316\n",
      "[3200]\tcv_agg's binary_logloss: 0.0587137 + 0.00137071\n",
      "[3250]\tcv_agg's binary_logloss: 0.0586952 + 0.00137221\n",
      "[3300]\tcv_agg's binary_logloss: 0.0586801 + 0.00137541\n",
      "[3350]\tcv_agg's binary_logloss: 0.0586654 + 0.00137464\n",
      "[3400]\tcv_agg's binary_logloss: 0.058649 + 0.00137356\n",
      "[3450]\tcv_agg's binary_logloss: 0.0586356 + 0.00137381\n",
      "[3500]\tcv_agg's binary_logloss: 0.0586179 + 0.00137444\n",
      "[3550]\tcv_agg's binary_logloss: 0.0585989 + 0.00137206\n",
      "[3600]\tcv_agg's binary_logloss: 0.0585814 + 0.00137046\n",
      "[3650]\tcv_agg's binary_logloss: 0.0585701 + 0.00137102\n",
      "[3700]\tcv_agg's binary_logloss: 0.0585566 + 0.00137324\n",
      "[3750]\tcv_agg's binary_logloss: 0.0585468 + 0.00137467\n",
      "[3800]\tcv_agg's binary_logloss: 0.0585339 + 0.00137162\n",
      "[3850]\tcv_agg's binary_logloss: 0.0585223 + 0.00137119\n",
      "[3900]\tcv_agg's binary_logloss: 0.0585172 + 0.00136887\n",
      "[3950]\tcv_agg's binary_logloss: 0.0585066 + 0.00136672\n",
      "[4000]\tcv_agg's binary_logloss: 0.0584948 + 0.00136925\n",
      "[4050]\tcv_agg's binary_logloss: 0.0584806 + 0.00136796\n",
      "[4100]\tcv_agg's binary_logloss: 0.0584759 + 0.00136586\n",
      "[4150]\tcv_agg's binary_logloss: 0.0584681 + 0.00136365\n",
      "[4200]\tcv_agg's binary_logloss: 0.0584576 + 0.00136445\n",
      "[4250]\tcv_agg's binary_logloss: 0.0584476 + 0.00136701\n",
      "[4300]\tcv_agg's binary_logloss: 0.0584428 + 0.00136477\n",
      "[4350]\tcv_agg's binary_logloss: 0.0584349 + 0.00136381\n",
      "[4400]\tcv_agg's binary_logloss: 0.0584291 + 0.00136315\n",
      "[4450]\tcv_agg's binary_logloss: 0.0584219 + 0.00136204\n",
      "[4500]\tcv_agg's binary_logloss: 0.0584149 + 0.00135993\n",
      "[4550]\tcv_agg's binary_logloss: 0.0584078 + 0.00136096\n",
      "[4600]\tcv_agg's binary_logloss: 0.058403 + 0.00136114\n",
      "[4650]\tcv_agg's binary_logloss: 0.0583954 + 0.00136248\n",
      "[4700]\tcv_agg's binary_logloss: 0.0583909 + 0.00136405\n",
      "[4750]\tcv_agg's binary_logloss: 0.0583862 + 0.00136202\n",
      "[4800]\tcv_agg's binary_logloss: 0.0583774 + 0.00136291\n",
      "[4850]\tcv_agg's binary_logloss: 0.0583782 + 0.00136033\n",
      "[4900]\tcv_agg's binary_logloss: 0.0583752 + 0.00136212\n",
      "[4950]\tcv_agg's binary_logloss: 0.0583688 + 0.00136383\n",
      "[5000]\tcv_agg's binary_logloss: 0.0583638 + 0.00136346\n",
      "[5050]\tcv_agg's binary_logloss: 0.0583594 + 0.00136286\n",
      "[5100]\tcv_agg's binary_logloss: 0.058352 + 0.00136347\n",
      "[5150]\tcv_agg's binary_logloss: 0.0583473 + 0.00136422\n",
      "[5200]\tcv_agg's binary_logloss: 0.0583434 + 0.00136572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c12788396c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\\n# Imagine now that you want to optimize num_leaves and\\n# learning_rate, and also use early stopping:\\nmax_depth_choices = [2**i for i in range(6,0,-1)]\\n\\n\\n# We will store the cross validation results in a simple list,\\n# with tuples in the form of (hyperparam dict, cv score):\\ncv_results = []\\n\\nfor depth_lv in max_depth_choices:\\n        print \"Starting cv for :\", depth_lv\\n\\n        lgb_params = {\\n        \\'learning_rate\\': 0.07,\\n        \\'max_depth\\': depth_lv,\\n        \\'task\\': \\'train\\', \\n        \\'boosting_type\\': \\'gbdt\\',\\n        \\'objective\\': \\'binary\\'}\\n        validation_summary = lgb.cv(lgb_params, dtrain_lgb_full, num_boost_round=8000, # any high number will do\\n                                                                     nfold=5,\\n                                                                     metrics=[\"binary_logloss\"],\\n                                                                     early_stopping_rounds=50, # Here it is\\n                                                                     verbose_eval=50)\\n        optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\\n            # Let\\'s just add the optimal number of trees (chosen by early stopping)\\n            # to the hyperparameter dictionary:\\n        lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\\n\\n           # And we append results to cv_results:\\n        cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    445\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mhandlerFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "max_depth_choices = [2**i for i in range(6,0,-1)]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for depth_lv in max_depth_choices:\n",
    "        print \"Starting cv for :\", depth_lv\n",
    "\n",
    "        lgb_params = {\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': depth_lv,\n",
    "        'task': 'train', \n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary'}\n",
    "        validation_summary = lgb.cv(lgb_params, dtrain_lgb_full, num_boost_round=8000, # any high number will do\n",
    "                                                                     nfold=5,\n",
    "                                                                     metrics=[\"binary_logloss\"],\n",
    "                                                                     early_stopping_rounds=50, # Here it is\n",
    "                                                                     verbose_eval=50)\n",
    "        optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "            # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "            # to the hyperparameter dictionary:\n",
    "        lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "           # And we append results to cv_results:\n",
    "        cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 2,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 166,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.061289759233353128),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 32,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 166,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.061289759233353128),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 16,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 169,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.061296296136130392),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 8,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 174,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.061290540483624867),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 4,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 652,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059134232722921717)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 4\n",
      "[50]\tcv_agg's binary_logloss: 0.0871718 + 0.000924393\n",
      "[100]\tcv_agg's binary_logloss: 0.0691146 + 0.00111743\n",
      "[150]\tcv_agg's binary_logloss: 0.0652982 + 0.00117947\n",
      "[200]\tcv_agg's binary_logloss: 0.063351 + 0.00125922\n",
      "[250]\tcv_agg's binary_logloss: 0.06209 + 0.00132284\n",
      "[300]\tcv_agg's binary_logloss: 0.0611852 + 0.00128709\n",
      "[350]\tcv_agg's binary_logloss: 0.0605569 + 0.00126531\n",
      "[400]\tcv_agg's binary_logloss: 0.0601424 + 0.00129053\n",
      "[450]\tcv_agg's binary_logloss: 0.0599214 + 0.00139953\n",
      "[500]\tcv_agg's binary_logloss: 0.0609497 + 0.00368726\n",
      "[550]\tcv_agg's binary_logloss: 0.0594651 + 0.00153832\n",
      "[600]\tcv_agg's binary_logloss: 0.0592846 + 0.00156972\n",
      "[650]\tcv_agg's binary_logloss: 0.0591398 + 0.00159503\n",
      "[700]\tcv_agg's binary_logloss: 0.059179 + 0.0014697\n",
      "Starting cv for : 5\n",
      "[50]\tcv_agg's binary_logloss: 0.0830615 + 0.000934899\n",
      "[100]\tcv_agg's binary_logloss: 0.0668972 + 0.0011535\n",
      "[150]\tcv_agg's binary_logloss: 0.0633273 + 0.00120217\n",
      "[200]\tcv_agg's binary_logloss: 0.0616516 + 0.00124609\n",
      "[250]\tcv_agg's binary_logloss: 0.0607358 + 0.00127237\n",
      "[300]\tcv_agg's binary_logloss: 0.0601194 + 0.00125114\n",
      "[350]\tcv_agg's binary_logloss: 0.059759 + 0.00122008\n",
      "[400]\tcv_agg's binary_logloss: 0.0594204 + 0.00120322\n",
      "[450]\tcv_agg's binary_logloss: 0.059232 + 0.00120838\n",
      "[500]\tcv_agg's binary_logloss: 0.059093 + 0.00132271\n",
      "[550]\tcv_agg's binary_logloss: 0.0590489 + 0.00136354\n",
      "[600]\tcv_agg's binary_logloss: 0.0589392 + 0.0013545\n",
      "[650]\tcv_agg's binary_logloss: 0.058878 + 0.00129267\n",
      "[700]\tcv_agg's binary_logloss: 0.0588155 + 0.00129009\n",
      "[750]\tcv_agg's binary_logloss: 0.0587778 + 0.00128881\n",
      "[800]\tcv_agg's binary_logloss: 0.0587521 + 0.00130174\n",
      "[850]\tcv_agg's binary_logloss: 0.0587217 + 0.00131433\n",
      "[900]\tcv_agg's binary_logloss: 0.0587375 + 0.00132232\n",
      "Starting cv for : 6\n",
      "[50]\tcv_agg's binary_logloss: 0.0805212 + 0.00093083\n",
      "[100]\tcv_agg's binary_logloss: 0.0655577 + 0.00108214\n",
      "[150]\tcv_agg's binary_logloss: 0.062365 + 0.00115141\n",
      "[200]\tcv_agg's binary_logloss: 0.0611501 + 0.00127428\n",
      "[250]\tcv_agg's binary_logloss: 0.0609601 + 0.00124888\n",
      "[300]\tcv_agg's binary_logloss: 0.0606294 + 0.00118747\n",
      "[350]\tcv_agg's binary_logloss: 0.0603194 + 0.00126809\n",
      "[400]\tcv_agg's binary_logloss: 0.0601681 + 0.00138462\n",
      "Starting cv for : 7\n",
      "[50]\tcv_agg's binary_logloss: 0.079802 + 0.000964998\n",
      "[100]\tcv_agg's binary_logloss: 0.0649709 + 0.0011387\n",
      "[150]\tcv_agg's binary_logloss: 0.0620582 + 0.00119134\n",
      "[200]\tcv_agg's binary_logloss: 0.0614859 + 0.00165979\n",
      "Starting cv for : 8\n",
      "[50]\tcv_agg's binary_logloss: 0.0796872 + 0.00100198\n",
      "[100]\tcv_agg's binary_logloss: 0.0646964 + 0.00119372\n",
      "[150]\tcv_agg's binary_logloss: 0.0618836 + 0.00117435\n",
      "[200]\tcv_agg's binary_logloss: 0.0614443 + 0.00163817\n",
      "CPU times: user 24min 34s, sys: 1min 10s, total: 25min 45s\n",
      "Wall time: 9min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "max_depth_choices = [4, 5, 6, 7, 8]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for depth_lv in max_depth_choices:\n",
    "    print \"Starting cv for :\", depth_lv\n",
    "        \n",
    "    lgb_params = {\n",
    "    'learning_rate': 0.07,\n",
    "    'max_depth': depth_lv,\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary'}\n",
    "    validation_summary = lgb.cv(lgb_params,\n",
    "                                                                 dtrain_lgb_full,\n",
    "                                                                 num_boost_round=4000, # any high number will do\n",
    "                                                                 nfold=5,\n",
    "                                                                 metrics=[\"binary_logloss\"],\n",
    "                                                                \n",
    "                                                                 early_stopping_rounds=50, # Here it is\n",
    "                                                                 verbose_eval=50)\n",
    "    optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "        # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "        # to the hyperparameter dictionary:\n",
    "    lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "       # And we append results to cv_results:\n",
    "    cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 8,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 652,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059134232722921717),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 863,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058714710889308762),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 390,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.060069403929643009),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 7,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 185,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.061276455942056052),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 8,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 174,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.061290540483624867)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2b\"></a>\n",
    "### Number of leaves tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 26\n",
      "[50]\tcv_agg's binary_logloss: 0.0831885 + 0.000873361\n",
      "[100]\tcv_agg's binary_logloss: 0.0669458 + 0.00106731\n",
      "[150]\tcv_agg's binary_logloss: 0.0634273 + 0.00120498\n",
      "[200]\tcv_agg's binary_logloss: 0.0618051 + 0.00123928\n",
      "[250]\tcv_agg's binary_logloss: 0.0609004 + 0.00115452\n",
      "[300]\tcv_agg's binary_logloss: 0.0602483 + 0.00123748\n",
      "[350]\tcv_agg's binary_logloss: 0.0598104 + 0.001191\n",
      "[400]\tcv_agg's binary_logloss: 0.0596042 + 0.00127749\n",
      "[450]\tcv_agg's binary_logloss: 0.0595659 + 0.00125506\n",
      "Starting cv for : 28\n",
      "[50]\tcv_agg's binary_logloss: 0.0831345 + 0.000933579\n",
      "[100]\tcv_agg's binary_logloss: 0.0669359 + 0.00105064\n",
      "[150]\tcv_agg's binary_logloss: 0.0633947 + 0.00111039\n",
      "[200]\tcv_agg's binary_logloss: 0.0618126 + 0.00120395\n",
      "[250]\tcv_agg's binary_logloss: 0.060867 + 0.00114495\n",
      "[300]\tcv_agg's binary_logloss: 0.0602526 + 0.0012272\n",
      "[350]\tcv_agg's binary_logloss: 0.0598436 + 0.00130651\n",
      "[400]\tcv_agg's binary_logloss: 0.0595814 + 0.00126024\n",
      "[450]\tcv_agg's binary_logloss: 0.0594444 + 0.0014058\n",
      "[500]\tcv_agg's binary_logloss: 0.0595475 + 0.00116322\n",
      "Starting cv for : 30\n",
      "[50]\tcv_agg's binary_logloss: 0.0830722 + 0.000933943\n",
      "[100]\tcv_agg's binary_logloss: 0.066897 + 0.00115663\n",
      "[150]\tcv_agg's binary_logloss: 0.0633666 + 0.00119878\n",
      "[200]\tcv_agg's binary_logloss: 0.061756 + 0.00127653\n",
      "[250]\tcv_agg's binary_logloss: 0.0607885 + 0.00130278\n",
      "[300]\tcv_agg's binary_logloss: 0.0602266 + 0.00134655\n",
      "[350]\tcv_agg's binary_logloss: 0.0599026 + 0.00134939\n",
      "[400]\tcv_agg's binary_logloss: 0.0595997 + 0.00136941\n",
      "[450]\tcv_agg's binary_logloss: 0.0595418 + 0.00130321\n",
      "[500]\tcv_agg's binary_logloss: 0.0594042 + 0.00124803\n",
      "[550]\tcv_agg's binary_logloss: 0.059226 + 0.00126045\n",
      "[600]\tcv_agg's binary_logloss: 0.0590892 + 0.00129455\n",
      "[650]\tcv_agg's binary_logloss: 0.0592617 + 0.00162754\n",
      "Starting cv for : 32\n",
      "[50]\tcv_agg's binary_logloss: 0.0830775 + 0.000947725\n",
      "[100]\tcv_agg's binary_logloss: 0.0668801 + 0.0011602\n",
      "[150]\tcv_agg's binary_logloss: 0.063359 + 0.00118238\n",
      "[200]\tcv_agg's binary_logloss: 0.0616613 + 0.00122287\n",
      "[250]\tcv_agg's binary_logloss: 0.0607141 + 0.00123837\n",
      "[300]\tcv_agg's binary_logloss: 0.0608925 + 0.000842459\n",
      "[350]\tcv_agg's binary_logloss: 0.0601205 + 0.00133668\n",
      "[400]\tcv_agg's binary_logloss: 0.0596999 + 0.00135619\n",
      "[450]\tcv_agg's binary_logloss: 0.0594255 + 0.00142839\n",
      "[500]\tcv_agg's binary_logloss: 0.0593604 + 0.00159287\n",
      "Starting cv for : 34\n",
      "[50]\tcv_agg's binary_logloss: 0.0830775 + 0.000947725\n",
      "[100]\tcv_agg's binary_logloss: 0.0668801 + 0.0011602\n",
      "[150]\tcv_agg's binary_logloss: 0.063359 + 0.00118238\n",
      "[200]\tcv_agg's binary_logloss: 0.0616613 + 0.00122287\n",
      "[250]\tcv_agg's binary_logloss: 0.0607141 + 0.00123837\n",
      "[300]\tcv_agg's binary_logloss: 0.0608925 + 0.000842459\n",
      "[350]\tcv_agg's binary_logloss: 0.0601205 + 0.00133668\n",
      "[400]\tcv_agg's binary_logloss: 0.0596999 + 0.00135619\n",
      "[450]\tcv_agg's binary_logloss: 0.0594255 + 0.00142839\n",
      "[500]\tcv_agg's binary_logloss: 0.0593604 + 0.00159287\n",
      "Starting cv for : 36\n",
      "[50]\tcv_agg's binary_logloss: 0.0830775 + 0.000947725\n",
      "[100]\tcv_agg's binary_logloss: 0.0668801 + 0.0011602\n",
      "[150]\tcv_agg's binary_logloss: 0.063359 + 0.00118238\n",
      "[200]\tcv_agg's binary_logloss: 0.0616613 + 0.00122287\n",
      "[250]\tcv_agg's binary_logloss: 0.0607141 + 0.00123837\n",
      "[300]\tcv_agg's binary_logloss: 0.0608925 + 0.000842459\n",
      "[350]\tcv_agg's binary_logloss: 0.0601205 + 0.00133668\n",
      "[400]\tcv_agg's binary_logloss: 0.0596999 + 0.00135619\n",
      "[450]\tcv_agg's binary_logloss: 0.0594255 + 0.00142839\n",
      "[500]\tcv_agg's binary_logloss: 0.0593604 + 0.00159287\n",
      "Starting cv for : 38\n",
      "[50]\tcv_agg's binary_logloss: 0.0830775 + 0.000947725\n",
      "[100]\tcv_agg's binary_logloss: 0.0668801 + 0.0011602\n",
      "[150]\tcv_agg's binary_logloss: 0.063359 + 0.00118238\n",
      "[200]\tcv_agg's binary_logloss: 0.0616613 + 0.00122287\n",
      "[250]\tcv_agg's binary_logloss: 0.0607141 + 0.00123837\n",
      "[300]\tcv_agg's binary_logloss: 0.0608925 + 0.000842459\n",
      "[350]\tcv_agg's binary_logloss: 0.0601205 + 0.00133668\n",
      "[400]\tcv_agg's binary_logloss: 0.0596999 + 0.00135619\n",
      "[450]\tcv_agg's binary_logloss: 0.0594255 + 0.00142839\n",
      "[500]\tcv_agg's binary_logloss: 0.0593604 + 0.00159287\n",
      "CPU times: user 36min 26s, sys: 1min 43s, total: 38min 10s\n",
      "Wall time: 13min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "#num_leaves = [2**i for i in range(3,9)]\n",
    "num_leaves = [i for i in range(26,39,2)]\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for leave in num_leaves:\n",
    "        print \"Starting cv for :\", leave\n",
    "\n",
    "        lgb_params = {\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': 5,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'num_leaves':leave}\n",
    "        validation_summary = lgb.cv(lgb_params,\n",
    "                                                                     dtrain_lgb_full,\n",
    "                                                                     num_boost_round=4000, # any high number will do\n",
    "                                                                     nfold=5,\n",
    "                                                                     metrics=[\"binary_logloss\"],\n",
    "\n",
    "                                                                     early_stopping_rounds=50, # Here it is\n",
    "                                                                     verbose_eval=50)\n",
    "        optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "            # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "            # to the hyperparameter dictionary:\n",
    "        lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "           # And we append results to cv_results:\n",
    "        cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 38,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 426,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059481169197700981),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 28,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 485,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059409553708127463),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 600,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059089151134795105),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 32,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 469,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.05934026100142694),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 34,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 469,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059340261001426954),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 36,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 469,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059340261001426954),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 38,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 469,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.059340261001426961)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2c\"></a>\n",
    "### Minimum data in leaves tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 100\n",
      "[50]\tcv_agg's binary_logloss: 0.0831346 + 0.000967489\n",
      "[100]\tcv_agg's binary_logloss: 0.0668719 + 0.00115047\n",
      "[150]\tcv_agg's binary_logloss: 0.0632964 + 0.00114442\n",
      "[200]\tcv_agg's binary_logloss: 0.0615439 + 0.0012028\n",
      "[250]\tcv_agg's binary_logloss: 0.0604831 + 0.00120993\n",
      "[300]\tcv_agg's binary_logloss: 0.0598046 + 0.0012104\n",
      "[350]\tcv_agg's binary_logloss: 0.0593307 + 0.00121701\n",
      "[400]\tcv_agg's binary_logloss: 0.0589858 + 0.00121954\n",
      "[450]\tcv_agg's binary_logloss: 0.0587705 + 0.00120732\n",
      "[500]\tcv_agg's binary_logloss: 0.0585762 + 0.00121146\n",
      "[550]\tcv_agg's binary_logloss: 0.0584311 + 0.00122463\n",
      "[600]\tcv_agg's binary_logloss: 0.05833 + 0.00122927\n",
      "[650]\tcv_agg's binary_logloss: 0.0582582 + 0.00123105\n",
      "[700]\tcv_agg's binary_logloss: 0.0582104 + 0.00122362\n",
      "[750]\tcv_agg's binary_logloss: 0.0581822 + 0.0012271\n",
      "[800]\tcv_agg's binary_logloss: 0.0581805 + 0.00122812\n",
      "Starting cv for : 200\n",
      "[50]\tcv_agg's binary_logloss: 0.0831769 + 0.000920764\n",
      "[100]\tcv_agg's binary_logloss: 0.0669205 + 0.0011558\n",
      "[150]\tcv_agg's binary_logloss: 0.0633409 + 0.0012162\n",
      "[200]\tcv_agg's binary_logloss: 0.0616319 + 0.00125899\n",
      "[250]\tcv_agg's binary_logloss: 0.0605274 + 0.00123886\n",
      "[300]\tcv_agg's binary_logloss: 0.05986 + 0.00128741\n",
      "[350]\tcv_agg's binary_logloss: 0.0593628 + 0.00129332\n",
      "[400]\tcv_agg's binary_logloss: 0.0590507 + 0.00130812\n",
      "[450]\tcv_agg's binary_logloss: 0.0588 + 0.00131526\n",
      "[500]\tcv_agg's binary_logloss: 0.0586114 + 0.00131403\n",
      "[550]\tcv_agg's binary_logloss: 0.0584825 + 0.00132824\n",
      "[600]\tcv_agg's binary_logloss: 0.0583838 + 0.00134008\n",
      "[650]\tcv_agg's binary_logloss: 0.0583125 + 0.00132675\n",
      "[700]\tcv_agg's binary_logloss: 0.0582694 + 0.00131724\n",
      "[750]\tcv_agg's binary_logloss: 0.0582449 + 0.00132952\n",
      "[800]\tcv_agg's binary_logloss: 0.0582244 + 0.00132749\n",
      "[850]\tcv_agg's binary_logloss: 0.0582179 + 0.00132416\n",
      "Starting cv for : 300\n",
      "[50]\tcv_agg's binary_logloss: 0.0831708 + 0.000890516\n",
      "[100]\tcv_agg's binary_logloss: 0.0668516 + 0.00113965\n",
      "[150]\tcv_agg's binary_logloss: 0.0632768 + 0.00122025\n",
      "[200]\tcv_agg's binary_logloss: 0.0615333 + 0.00127594\n",
      "[250]\tcv_agg's binary_logloss: 0.0604488 + 0.0012237\n",
      "[300]\tcv_agg's binary_logloss: 0.0597356 + 0.00124286\n",
      "[350]\tcv_agg's binary_logloss: 0.0592595 + 0.00127428\n",
      "[400]\tcv_agg's binary_logloss: 0.0589425 + 0.00127602\n",
      "[450]\tcv_agg's binary_logloss: 0.0587184 + 0.00128271\n",
      "[500]\tcv_agg's binary_logloss: 0.0585374 + 0.00128282\n",
      "[550]\tcv_agg's binary_logloss: 0.0584035 + 0.00128451\n",
      "[600]\tcv_agg's binary_logloss: 0.0583118 + 0.00128005\n",
      "[650]\tcv_agg's binary_logloss: 0.0582291 + 0.00129137\n",
      "[700]\tcv_agg's binary_logloss: 0.0581761 + 0.00128574\n",
      "[750]\tcv_agg's binary_logloss: 0.0581483 + 0.00128613\n",
      "[800]\tcv_agg's binary_logloss: 0.0581281 + 0.00127808\n",
      "[850]\tcv_agg's binary_logloss: 0.058113 + 0.00128853\n",
      "Starting cv for : 400\n",
      "[50]\tcv_agg's binary_logloss: 0.0832863 + 0.000919878\n",
      "[100]\tcv_agg's binary_logloss: 0.0669521 + 0.0011324\n",
      "[150]\tcv_agg's binary_logloss: 0.0633766 + 0.0011988\n",
      "[200]\tcv_agg's binary_logloss: 0.0616218 + 0.00125007\n",
      "[250]\tcv_agg's binary_logloss: 0.0605704 + 0.00125964\n",
      "[300]\tcv_agg's binary_logloss: 0.0598469 + 0.00126734\n",
      "[350]\tcv_agg's binary_logloss: 0.0593535 + 0.00131545\n",
      "[400]\tcv_agg's binary_logloss: 0.0590063 + 0.00130248\n",
      "[450]\tcv_agg's binary_logloss: 0.058746 + 0.00131757\n",
      "[500]\tcv_agg's binary_logloss: 0.0585531 + 0.00132555\n",
      "[550]\tcv_agg's binary_logloss: 0.0583935 + 0.00132971\n",
      "[600]\tcv_agg's binary_logloss: 0.0582997 + 0.00131174\n",
      "[650]\tcv_agg's binary_logloss: 0.0582228 + 0.00132535\n",
      "[700]\tcv_agg's binary_logloss: 0.0581747 + 0.0013287\n",
      "[750]\tcv_agg's binary_logloss: 0.0581332 + 0.00132782\n",
      "[800]\tcv_agg's binary_logloss: 0.0581003 + 0.00133863\n",
      "[850]\tcv_agg's binary_logloss: 0.0580844 + 0.00133435\n",
      "[900]\tcv_agg's binary_logloss: 0.0580937 + 0.00134313\n",
      "Starting cv for : 500\n",
      "[50]\tcv_agg's binary_logloss: 0.0834102 + 0.000926782\n",
      "[100]\tcv_agg's binary_logloss: 0.0670481 + 0.00112176\n",
      "[150]\tcv_agg's binary_logloss: 0.0634701 + 0.00113857\n",
      "[200]\tcv_agg's binary_logloss: 0.061673 + 0.00123389\n",
      "[250]\tcv_agg's binary_logloss: 0.0605671 + 0.00122899\n",
      "[300]\tcv_agg's binary_logloss: 0.0598601 + 0.00125482\n",
      "[350]\tcv_agg's binary_logloss: 0.0593577 + 0.00131465\n",
      "[400]\tcv_agg's binary_logloss: 0.0590064 + 0.00129375\n",
      "[450]\tcv_agg's binary_logloss: 0.0587608 + 0.00129327\n",
      "[500]\tcv_agg's binary_logloss: 0.0585709 + 0.00132744\n",
      "[550]\tcv_agg's binary_logloss: 0.0584253 + 0.00132553\n",
      "[600]\tcv_agg's binary_logloss: 0.0583303 + 0.00132649\n",
      "[650]\tcv_agg's binary_logloss: 0.0582575 + 0.00133131\n",
      "[700]\tcv_agg's binary_logloss: 0.0581918 + 0.00133559\n",
      "[750]\tcv_agg's binary_logloss: 0.0581604 + 0.00132023\n",
      "[800]\tcv_agg's binary_logloss: 0.0581266 + 0.00133504\n",
      "[850]\tcv_agg's binary_logloss: 0.0581194 + 0.00134181\n",
      "[900]\tcv_agg's binary_logloss: 0.0581099 + 0.00134294\n",
      "[950]\tcv_agg's binary_logloss: 0.0581081 + 0.00133855\n",
      "Starting cv for : 600\n",
      "[50]\tcv_agg's binary_logloss: 0.0834477 + 0.000850062\n",
      "[100]\tcv_agg's binary_logloss: 0.0671178 + 0.00105531\n",
      "[150]\tcv_agg's binary_logloss: 0.0635076 + 0.00113421\n",
      "[200]\tcv_agg's binary_logloss: 0.0617242 + 0.00122836\n",
      "[250]\tcv_agg's binary_logloss: 0.0605944 + 0.0012243\n",
      "[300]\tcv_agg's binary_logloss: 0.0598658 + 0.00122819\n",
      "[350]\tcv_agg's binary_logloss: 0.0593454 + 0.00121573\n",
      "[400]\tcv_agg's binary_logloss: 0.0589813 + 0.00121171\n",
      "[450]\tcv_agg's binary_logloss: 0.0587223 + 0.00123244\n",
      "[500]\tcv_agg's binary_logloss: 0.0585415 + 0.00125062\n",
      "[550]\tcv_agg's binary_logloss: 0.058411 + 0.00124437\n",
      "[600]\tcv_agg's binary_logloss: 0.0583002 + 0.00125958\n",
      "[650]\tcv_agg's binary_logloss: 0.0581992 + 0.00125633\n",
      "[700]\tcv_agg's binary_logloss: 0.0581346 + 0.0012652\n",
      "[750]\tcv_agg's binary_logloss: 0.0581102 + 0.00125896\n",
      "[800]\tcv_agg's binary_logloss: 0.0580853 + 0.00125172\n",
      "[850]\tcv_agg's binary_logloss: 0.0580755 + 0.00124896\n",
      "Starting cv for : 700\n",
      "[50]\tcv_agg's binary_logloss: 0.0835264 + 0.000939129\n",
      "[100]\tcv_agg's binary_logloss: 0.0671087 + 0.00114068\n",
      "[150]\tcv_agg's binary_logloss: 0.0635597 + 0.00112376\n",
      "[200]\tcv_agg's binary_logloss: 0.0617701 + 0.00119139\n",
      "[250]\tcv_agg's binary_logloss: 0.0606304 + 0.00121229\n",
      "[300]\tcv_agg's binary_logloss: 0.0598671 + 0.0012058\n",
      "[350]\tcv_agg's binary_logloss: 0.0593436 + 0.00122094\n",
      "[400]\tcv_agg's binary_logloss: 0.0589942 + 0.00123296\n",
      "[450]\tcv_agg's binary_logloss: 0.0587407 + 0.00124325\n",
      "[500]\tcv_agg's binary_logloss: 0.0585502 + 0.00123904\n",
      "[550]\tcv_agg's binary_logloss: 0.0584065 + 0.00124994\n",
      "[600]\tcv_agg's binary_logloss: 0.0583156 + 0.00125249\n",
      "[650]\tcv_agg's binary_logloss: 0.0582303 + 0.00125957\n",
      "[700]\tcv_agg's binary_logloss: 0.0581867 + 0.00124958\n",
      "[750]\tcv_agg's binary_logloss: 0.0581462 + 0.00124747\n",
      "[800]\tcv_agg's binary_logloss: 0.0581105 + 0.00124856\n",
      "[850]\tcv_agg's binary_logloss: 0.0580988 + 0.00125444\n",
      "[900]\tcv_agg's binary_logloss: 0.0580992 + 0.00126169\n",
      "[950]\tcv_agg's binary_logloss: 0.0580858 + 0.0012597\n",
      "[1000]\tcv_agg's binary_logloss: 0.058095 + 0.00125192\n",
      "Starting cv for : 800\n",
      "[50]\tcv_agg's binary_logloss: 0.0834943 + 0.000866398\n",
      "[100]\tcv_agg's binary_logloss: 0.0671689 + 0.00110265\n",
      "[150]\tcv_agg's binary_logloss: 0.0636148 + 0.00117202\n",
      "[200]\tcv_agg's binary_logloss: 0.0618479 + 0.00123199\n",
      "[250]\tcv_agg's binary_logloss: 0.0606743 + 0.00124655\n",
      "[300]\tcv_agg's binary_logloss: 0.0599297 + 0.00125384\n",
      "[350]\tcv_agg's binary_logloss: 0.0594147 + 0.0012806\n",
      "[400]\tcv_agg's binary_logloss: 0.0590703 + 0.00129388\n",
      "[450]\tcv_agg's binary_logloss: 0.0587907 + 0.00131218\n",
      "[500]\tcv_agg's binary_logloss: 0.0586035 + 0.00130293\n",
      "[550]\tcv_agg's binary_logloss: 0.0584621 + 0.00130045\n",
      "[600]\tcv_agg's binary_logloss: 0.0583434 + 0.00129619\n",
      "[650]\tcv_agg's binary_logloss: 0.0582755 + 0.00130082\n",
      "[700]\tcv_agg's binary_logloss: 0.0582151 + 0.00131061\n",
      "[750]\tcv_agg's binary_logloss: 0.058178 + 0.00130898\n",
      "[800]\tcv_agg's binary_logloss: 0.0581308 + 0.00130013\n",
      "[850]\tcv_agg's binary_logloss: 0.0581151 + 0.00130833\n",
      "[900]\tcv_agg's binary_logloss: 0.0581109 + 0.00129972\n",
      "Starting cv for : 900\n",
      "[50]\tcv_agg's binary_logloss: 0.0835652 + 0.000878186\n",
      "[100]\tcv_agg's binary_logloss: 0.0671276 + 0.00110571\n",
      "[150]\tcv_agg's binary_logloss: 0.0635922 + 0.00116452\n",
      "[200]\tcv_agg's binary_logloss: 0.0617807 + 0.00125006\n",
      "[250]\tcv_agg's binary_logloss: 0.0606874 + 0.00125756\n",
      "[300]\tcv_agg's binary_logloss: 0.0599216 + 0.00125488\n",
      "[350]\tcv_agg's binary_logloss: 0.0594306 + 0.0012748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tcv_agg's binary_logloss: 0.0590539 + 0.00129524\n",
      "[450]\tcv_agg's binary_logloss: 0.0587889 + 0.0013012\n",
      "[500]\tcv_agg's binary_logloss: 0.0586146 + 0.00129328\n",
      "[550]\tcv_agg's binary_logloss: 0.058465 + 0.00129035\n",
      "[600]\tcv_agg's binary_logloss: 0.0583434 + 0.00128287\n",
      "[650]\tcv_agg's binary_logloss: 0.058274 + 0.00128325\n",
      "[700]\tcv_agg's binary_logloss: 0.0582073 + 0.00129511\n",
      "[750]\tcv_agg's binary_logloss: 0.0581597 + 0.00132433\n",
      "[800]\tcv_agg's binary_logloss: 0.0581181 + 0.00131579\n",
      "[850]\tcv_agg's binary_logloss: 0.0580805 + 0.00131713\n",
      "[900]\tcv_agg's binary_logloss: 0.0580926 + 0.00132517\n",
      "Starting cv for : 1000\n",
      "[50]\tcv_agg's binary_logloss: 0.0836808 + 0.000876187\n",
      "[100]\tcv_agg's binary_logloss: 0.0672423 + 0.00105487\n",
      "[150]\tcv_agg's binary_logloss: 0.063705 + 0.00118132\n",
      "[200]\tcv_agg's binary_logloss: 0.0618975 + 0.0012338\n",
      "[250]\tcv_agg's binary_logloss: 0.0607613 + 0.00125723\n",
      "[300]\tcv_agg's binary_logloss: 0.0599894 + 0.00127334\n",
      "[350]\tcv_agg's binary_logloss: 0.0594613 + 0.00125411\n",
      "[400]\tcv_agg's binary_logloss: 0.0591228 + 0.00126036\n",
      "[450]\tcv_agg's binary_logloss: 0.0588439 + 0.00128102\n",
      "[500]\tcv_agg's binary_logloss: 0.0586242 + 0.00128552\n",
      "[550]\tcv_agg's binary_logloss: 0.0584841 + 0.00129573\n",
      "[600]\tcv_agg's binary_logloss: 0.0583551 + 0.00128492\n",
      "[650]\tcv_agg's binary_logloss: 0.0582549 + 0.00128643\n",
      "[700]\tcv_agg's binary_logloss: 0.0582027 + 0.00128521\n",
      "[750]\tcv_agg's binary_logloss: 0.058151 + 0.0012873\n",
      "[800]\tcv_agg's binary_logloss: 0.0581159 + 0.00128276\n",
      "[850]\tcv_agg's binary_logloss: 0.0580764 + 0.00128118\n",
      "[900]\tcv_agg's binary_logloss: 0.0580708 + 0.00128329\n",
      "[950]\tcv_agg's binary_logloss: 0.0580537 + 0.00129751\n",
      "[1000]\tcv_agg's binary_logloss: 0.0580566 + 0.00130325\n",
      "CPU times: user 1h 29min 6s, sys: 4min 3s, total: 1h 33min 9s\n",
      "Wall time: 35min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "min_data_leaves = [i for i in range(100,1001,100)]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for data_leaf in min_data_leaves:\n",
    "        print \"Starting cv for :\", data_leaf\n",
    "\n",
    "        lgb_params = {\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': 5,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'num_leaves':30,\n",
    "        'min_data_in_leaf':data_leaf}\n",
    "        validation_summary = lgb.cv(lgb_params,\n",
    "                                                                     dtrain_lgb_full,\n",
    "                                                                     num_boost_round=4000, # any high number will do\n",
    "                                                                     nfold=5,\n",
    "                                                                     metrics=[\"binary_logloss\"],\n",
    "\n",
    "                                                                     early_stopping_rounds=50, # Here it is\n",
    "                                                                     verbose_eval=50)\n",
    "        optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "            # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "            # to the hyperparameter dictionary:\n",
    "        lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "           # And we append results to cv_results:\n",
    "        cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 1000,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 784,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.05816980055568273),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 200,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 828,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058212185036541429),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 300,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 840,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058104363191568219),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 400,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 865,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058080375667257621),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 500,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 933,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058101291939149605),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 842,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058069880724336678),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 700,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 950,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058085769905253916),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 800,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 867,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058104863061841205),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 900,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 866,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.05807894545210459),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 1000,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 958,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058050451123368339)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2d\"></a>\n",
    "### Lasso regularization tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 0.0\n",
      "[100]\tcv_agg's binary_logloss: 0.0671178 + 0.00105531\n",
      "[200]\tcv_agg's binary_logloss: 0.0617242 + 0.00122836\n",
      "[300]\tcv_agg's binary_logloss: 0.0598658 + 0.00122819\n",
      "[400]\tcv_agg's binary_logloss: 0.0589813 + 0.00121171\n",
      "[500]\tcv_agg's binary_logloss: 0.0585415 + 0.00125062\n",
      "[600]\tcv_agg's binary_logloss: 0.0583002 + 0.00125958\n",
      "[700]\tcv_agg's binary_logloss: 0.0581346 + 0.0012652\n",
      "[800]\tcv_agg's binary_logloss: 0.0580853 + 0.00125172\n",
      "Starting cv for : 0.1\n",
      "[100]\tcv_agg's binary_logloss: 0.0671052 + 0.00113217\n",
      "[200]\tcv_agg's binary_logloss: 0.0617581 + 0.00122411\n",
      "[300]\tcv_agg's binary_logloss: 0.0598881 + 0.00125013\n",
      "[400]\tcv_agg's binary_logloss: 0.0590422 + 0.00125553\n",
      "[500]\tcv_agg's binary_logloss: 0.0585901 + 0.00126743\n",
      "[600]\tcv_agg's binary_logloss: 0.0583502 + 0.00127287\n",
      "[700]\tcv_agg's binary_logloss: 0.0582019 + 0.00128245\n",
      "[800]\tcv_agg's binary_logloss: 0.0581483 + 0.00128187\n",
      "Starting cv for : 0.2\n",
      "[100]\tcv_agg's binary_logloss: 0.0671398 + 0.00108318\n",
      "[200]\tcv_agg's binary_logloss: 0.0617631 + 0.00119421\n",
      "[300]\tcv_agg's binary_logloss: 0.0598541 + 0.00121907\n",
      "[400]\tcv_agg's binary_logloss: 0.0589842 + 0.00126094\n",
      "[500]\tcv_agg's binary_logloss: 0.0585169 + 0.00125806\n",
      "[600]\tcv_agg's binary_logloss: 0.0582664 + 0.00128455\n",
      "[700]\tcv_agg's binary_logloss: 0.0581085 + 0.001281\n",
      "[800]\tcv_agg's binary_logloss: 0.058064 + 0.00129084\n",
      "[900]\tcv_agg's binary_logloss: 0.0580327 + 0.00129\n",
      "Starting cv for : 0.3\n",
      "[100]\tcv_agg's binary_logloss: 0.0670986 + 0.0011335\n",
      "[200]\tcv_agg's binary_logloss: 0.0616703 + 0.00127716\n",
      "[300]\tcv_agg's binary_logloss: 0.0597952 + 0.00126116\n",
      "[400]\tcv_agg's binary_logloss: 0.0589155 + 0.00128551\n",
      "[500]\tcv_agg's binary_logloss: 0.0584735 + 0.00126456\n",
      "[600]\tcv_agg's binary_logloss: 0.0582217 + 0.00126653\n",
      "[700]\tcv_agg's binary_logloss: 0.0580933 + 0.00128728\n",
      "[800]\tcv_agg's binary_logloss: 0.0580397 + 0.00129525\n",
      "[900]\tcv_agg's binary_logloss: 0.0580161 + 0.00130746\n",
      "Starting cv for : 0.4\n",
      "[100]\tcv_agg's binary_logloss: 0.0671204 + 0.00113594\n",
      "[200]\tcv_agg's binary_logloss: 0.0617009 + 0.00125449\n",
      "[300]\tcv_agg's binary_logloss: 0.0598276 + 0.00124893\n",
      "[400]\tcv_agg's binary_logloss: 0.0589491 + 0.00129763\n",
      "[500]\tcv_agg's binary_logloss: 0.058496 + 0.00128694\n",
      "[600]\tcv_agg's binary_logloss: 0.0582391 + 0.00127886\n",
      "[700]\tcv_agg's binary_logloss: 0.0581178 + 0.00128642\n",
      "[800]\tcv_agg's binary_logloss: 0.0580529 + 0.00127593\n",
      "[900]\tcv_agg's binary_logloss: 0.0580385 + 0.00127651\n",
      "Starting cv for : 0.5\n",
      "[100]\tcv_agg's binary_logloss: 0.0671234 + 0.0011127\n",
      "[200]\tcv_agg's binary_logloss: 0.0617261 + 0.00119856\n",
      "[300]\tcv_agg's binary_logloss: 0.0598713 + 0.00122508\n",
      "[400]\tcv_agg's binary_logloss: 0.058948 + 0.0012646\n",
      "[500]\tcv_agg's binary_logloss: 0.0584891 + 0.00128463\n",
      "[600]\tcv_agg's binary_logloss: 0.058247 + 0.0012849\n",
      "[700]\tcv_agg's binary_logloss: 0.0581106 + 0.00129481\n",
      "[800]\tcv_agg's binary_logloss: 0.0580695 + 0.00128606\n",
      "[900]\tcv_agg's binary_logloss: 0.0580504 + 0.00128607\n",
      "Starting cv for : 0.6\n",
      "[100]\tcv_agg's binary_logloss: 0.0671892 + 0.00107324\n",
      "[200]\tcv_agg's binary_logloss: 0.0617818 + 0.00118058\n",
      "[300]\tcv_agg's binary_logloss: 0.0598587 + 0.00119875\n",
      "[400]\tcv_agg's binary_logloss: 0.0589782 + 0.00121663\n",
      "[500]\tcv_agg's binary_logloss: 0.0585136 + 0.00122366\n",
      "[600]\tcv_agg's binary_logloss: 0.058247 + 0.00123\n",
      "[700]\tcv_agg's binary_logloss: 0.0581383 + 0.00122383\n",
      "[800]\tcv_agg's binary_logloss: 0.0580683 + 0.00124018\n",
      "[900]\tcv_agg's binary_logloss: 0.0580532 + 0.00123326\n",
      "Starting cv for : 0.7\n",
      "[100]\tcv_agg's binary_logloss: 0.0670936 + 0.00111595\n",
      "[200]\tcv_agg's binary_logloss: 0.0617358 + 0.00123353\n",
      "[300]\tcv_agg's binary_logloss: 0.0598369 + 0.00124109\n",
      "[400]\tcv_agg's binary_logloss: 0.0589612 + 0.00126699\n",
      "[500]\tcv_agg's binary_logloss: 0.0584838 + 0.00125933\n",
      "[600]\tcv_agg's binary_logloss: 0.0582112 + 0.00127688\n",
      "[700]\tcv_agg's binary_logloss: 0.0580769 + 0.00123661\n",
      "[800]\tcv_agg's binary_logloss: 0.0580311 + 0.00124117\n",
      "[900]\tcv_agg's binary_logloss: 0.0580033 + 0.00124169\n",
      "Starting cv for : 0.8\n",
      "[100]\tcv_agg's binary_logloss: 0.0671399 + 0.0011274\n",
      "[200]\tcv_agg's binary_logloss: 0.06173 + 0.00127537\n",
      "[300]\tcv_agg's binary_logloss: 0.0598549 + 0.00129127\n",
      "[400]\tcv_agg's binary_logloss: 0.0589449 + 0.00130719\n",
      "[500]\tcv_agg's binary_logloss: 0.0584942 + 0.00131177\n",
      "[600]\tcv_agg's binary_logloss: 0.058237 + 0.0012968\n",
      "[700]\tcv_agg's binary_logloss: 0.0581006 + 0.00129731\n",
      "[800]\tcv_agg's binary_logloss: 0.0580308 + 0.0012998\n",
      "[900]\tcv_agg's binary_logloss: 0.0580206 + 0.00130954\n",
      "Starting cv for : 0.9\n",
      "[100]\tcv_agg's binary_logloss: 0.0671641 + 0.00111173\n",
      "[200]\tcv_agg's binary_logloss: 0.061736 + 0.0012449\n",
      "[300]\tcv_agg's binary_logloss: 0.0598387 + 0.00125846\n",
      "[400]\tcv_agg's binary_logloss: 0.0589507 + 0.00129285\n",
      "[500]\tcv_agg's binary_logloss: 0.0584713 + 0.00129898\n",
      "[600]\tcv_agg's binary_logloss: 0.0582163 + 0.00129744\n",
      "[700]\tcv_agg's binary_logloss: 0.058094 + 0.00128193\n",
      "[800]\tcv_agg's binary_logloss: 0.0580375 + 0.0012763\n",
      "Starting cv for : 1.0\n",
      "[100]\tcv_agg's binary_logloss: 0.0670972 + 0.00112567\n",
      "[200]\tcv_agg's binary_logloss: 0.0617091 + 0.00124409\n",
      "[300]\tcv_agg's binary_logloss: 0.0597988 + 0.00124866\n",
      "[400]\tcv_agg's binary_logloss: 0.0589259 + 0.00129756\n",
      "[500]\tcv_agg's binary_logloss: 0.0584337 + 0.0012874\n",
      "[600]\tcv_agg's binary_logloss: 0.0581828 + 0.00129757\n",
      "[700]\tcv_agg's binary_logloss: 0.0580572 + 0.00130455\n",
      "[800]\tcv_agg's binary_logloss: 0.0579908 + 0.0012903\n",
      "[900]\tcv_agg's binary_logloss: 0.0579824 + 0.00128263\n",
      "CPU times: user 1h 36min 9s, sys: 4min 7s, total: 1h 40min 17s\n",
      "Wall time: 36min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "reg_lambda = [i/10.0 for i in range(0,11,1)]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for lam in reg_lambda:\n",
    "    print \"Starting cv for :\", lam\n",
    "        \n",
    "    lgb_params = {\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': 5,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'num_leaves':30,\n",
    "        'min_data_in_leaf':600,\n",
    "        'lambda_l1':lam}\n",
    "    validation_summary = lgb.cv(lgb_params,\n",
    "                                                                 dtrain_lgb_full,\n",
    "                                                                 num_boost_round=4000, # any high number will do\n",
    "                                                                 nfold=5,\n",
    "                                                                 metrics=[\"binary_logloss\"],\n",
    "                                                                \n",
    "                                                                 early_stopping_rounds=50, # Here it is\n",
    "                                                                 verbose_eval=100)\n",
    "    optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "        # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "        # to the hyperparameter dictionary:\n",
    "    lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "       # And we append results to cv_results:\n",
    "    cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 1.0,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 842,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058069880724337761),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.1,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 781,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058136296830961463),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.2,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 853,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058028098980590102),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.3,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 883,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058010108895521197),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.4,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 909,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058035760837451579),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 939,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058043042853279679),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 925,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058048156595087982),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 865,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057998031378193371),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.8,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 884,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058014237463428708),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.9,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 811,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058031699194813414),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 1.0,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 880,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.05797726389493759)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2e\"></a>\n",
    "### Ridge regularization tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 0.0\n",
      "[100]\tcv_agg's binary_logloss: 0.0670936 + 0.00111595\n",
      "[200]\tcv_agg's binary_logloss: 0.0617358 + 0.00123353\n",
      "[300]\tcv_agg's binary_logloss: 0.0598369 + 0.00124109\n",
      "[400]\tcv_agg's binary_logloss: 0.0589612 + 0.00126699\n",
      "[500]\tcv_agg's binary_logloss: 0.0584838 + 0.00125933\n",
      "[600]\tcv_agg's binary_logloss: 0.0582112 + 0.00127688\n",
      "[700]\tcv_agg's binary_logloss: 0.0580769 + 0.00123661\n",
      "[800]\tcv_agg's binary_logloss: 0.0580311 + 0.00124117\n",
      "[900]\tcv_agg's binary_logloss: 0.0580033 + 0.00124169\n",
      "Starting cv for : 0.2\n",
      "[100]\tcv_agg's binary_logloss: 0.067141 + 0.00111777\n",
      "[200]\tcv_agg's binary_logloss: 0.0617542 + 0.00122671\n",
      "[300]\tcv_agg's binary_logloss: 0.0598457 + 0.00126481\n",
      "[400]\tcv_agg's binary_logloss: 0.0589388 + 0.00128197\n",
      "[500]\tcv_agg's binary_logloss: 0.0584603 + 0.00128002\n",
      "[600]\tcv_agg's binary_logloss: 0.0582161 + 0.00126943\n",
      "[700]\tcv_agg's binary_logloss: 0.0580948 + 0.00127072\n",
      "[800]\tcv_agg's binary_logloss: 0.0580352 + 0.00125895\n",
      "Starting cv for : 0.4\n",
      "[100]\tcv_agg's binary_logloss: 0.0672052 + 0.00111607\n",
      "[200]\tcv_agg's binary_logloss: 0.0617805 + 0.00129775\n",
      "[300]\tcv_agg's binary_logloss: 0.0598823 + 0.00126254\n",
      "[400]\tcv_agg's binary_logloss: 0.0589757 + 0.0012665\n",
      "[500]\tcv_agg's binary_logloss: 0.0585004 + 0.00126951\n",
      "[600]\tcv_agg's binary_logloss: 0.058253 + 0.00127035\n",
      "[700]\tcv_agg's binary_logloss: 0.0581031 + 0.00128189\n",
      "[800]\tcv_agg's binary_logloss: 0.0580361 + 0.0012866\n",
      "[900]\tcv_agg's binary_logloss: 0.0580366 + 0.00127628\n",
      "Starting cv for : 0.6\n",
      "[100]\tcv_agg's binary_logloss: 0.0671315 + 0.00113486\n",
      "[200]\tcv_agg's binary_logloss: 0.061707 + 0.00123363\n",
      "[300]\tcv_agg's binary_logloss: 0.0598522 + 0.00125668\n",
      "[400]\tcv_agg's binary_logloss: 0.0589379 + 0.00128727\n",
      "[500]\tcv_agg's binary_logloss: 0.0584615 + 0.00128113\n",
      "[600]\tcv_agg's binary_logloss: 0.0582034 + 0.00128495\n",
      "[700]\tcv_agg's binary_logloss: 0.0580649 + 0.0012964\n",
      "[800]\tcv_agg's binary_logloss: 0.0579965 + 0.0013044\n",
      "[900]\tcv_agg's binary_logloss: 0.0579588 + 0.00129068\n",
      "Starting cv for : 0.8\n",
      "[100]\tcv_agg's binary_logloss: 0.0672462 + 0.00112388\n",
      "[200]\tcv_agg's binary_logloss: 0.0618431 + 0.00125632\n",
      "[300]\tcv_agg's binary_logloss: 0.0598794 + 0.00128141\n",
      "[400]\tcv_agg's binary_logloss: 0.0589829 + 0.00132513\n",
      "[500]\tcv_agg's binary_logloss: 0.0585107 + 0.00132537\n",
      "[600]\tcv_agg's binary_logloss: 0.0582495 + 0.00130638\n",
      "[700]\tcv_agg's binary_logloss: 0.0581017 + 0.00130582\n",
      "[800]\tcv_agg's binary_logloss: 0.0580453 + 0.00128832\n",
      "[900]\tcv_agg's binary_logloss: 0.0580274 + 0.00129414\n",
      "Starting cv for : 1.0\n",
      "[100]\tcv_agg's binary_logloss: 0.0671663 + 0.00115776\n",
      "[200]\tcv_agg's binary_logloss: 0.0618573 + 0.0012727\n",
      "[300]\tcv_agg's binary_logloss: 0.059888 + 0.0012706\n",
      "[400]\tcv_agg's binary_logloss: 0.0589577 + 0.00128904\n",
      "[500]\tcv_agg's binary_logloss: 0.0584998 + 0.00130116\n",
      "[600]\tcv_agg's binary_logloss: 0.0582173 + 0.0012959\n",
      "[700]\tcv_agg's binary_logloss: 0.0580848 + 0.00131127\n",
      "[800]\tcv_agg's binary_logloss: 0.0580201 + 0.00131689\n",
      "[900]\tcv_agg's binary_logloss: 0.0579903 + 0.00129898\n",
      "CPU times: user 53min 10s, sys: 2min 18s, total: 55min 29s\n",
      "Wall time: 19min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "reg_lambda = [i/10.0 for i in range(0,11,2)]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for lam in reg_lambda:\n",
    "    print \"Starting cv for :\", lam\n",
    "        \n",
    "    lgb_params = {\n",
    "        'learning_rate': 0.07,\n",
    "        'max_depth': 5,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'num_leaves':30,\n",
    "        'min_data_in_leaf':600,\n",
    "        'lambda_l1': 0.7,\n",
    "        'lambda_l2':lam}\n",
    "    validation_summary = lgb.cv(lgb_params,\n",
    "                                                                 dtrain_lgb_full,\n",
    "                                                                 num_boost_round=4000, # any high number will do\n",
    "                                                                 nfold=5,\n",
    "                                                                 metrics=[\"binary_logloss\"],\n",
    "                                                                \n",
    "                                                                 early_stopping_rounds=50, # Here it is\n",
    "                                                                 verbose_eval=100)\n",
    "    optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "        # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "        # to the hyperparameter dictionary:\n",
    "    lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "       # And we append results to cv_results:\n",
    "    cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 1.0,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 865,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057998031378193392),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.2,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 830,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058028643995671425),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.4,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 851,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058025311309216107),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 892,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057953036288266792),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.8,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 939,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.058024449558822355),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 1.0,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 875,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057983657428512657)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2f\"></a>\n",
    "### Max bin tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 200\n",
      "[20]\tcv_agg's binary_logloss: 0.0912299 + 0.000200594\n",
      "[40]\tcv_agg's binary_logloss: 0.0307431 + 0.000258411\n",
      "[60]\tcv_agg's binary_logloss: 0.0202871 + 0.00019821\n",
      "[80]\tcv_agg's binary_logloss: 0.0171365 + 0.000198929\n",
      "[100]\tcv_agg's binary_logloss: 0.0162793 + 0.000202121\n",
      "[120]\tcv_agg's binary_logloss: 0.0158437 + 0.00021699\n",
      "[140]\tcv_agg's binary_logloss: 0.0156268 + 0.000208391\n",
      "[160]\tcv_agg's binary_logloss: 0.0154985 + 0.000232281\n",
      "[180]\tcv_agg's binary_logloss: 0.0154395 + 0.000249458\n",
      "[200]\tcv_agg's binary_logloss: 0.0154121 + 0.000244705\n",
      "[220]\tcv_agg's binary_logloss: 0.0153975 + 0.000251805\n",
      "[240]\tcv_agg's binary_logloss: 0.0153922 + 0.000257281\n",
      "[260]\tcv_agg's binary_logloss: 0.01538 + 0.000251256\n",
      "[280]\tcv_agg's binary_logloss: 0.0153969 + 0.00027378\n",
      "[300]\tcv_agg's binary_logloss: 0.0154232 + 0.000285013\n",
      "Starting cv for : 250\n",
      "[20]\tcv_agg's binary_logloss: 0.0912299 + 0.000200594\n",
      "[40]\tcv_agg's binary_logloss: 0.0307431 + 0.000258411\n",
      "[60]\tcv_agg's binary_logloss: 0.0202871 + 0.00019821\n",
      "[80]\tcv_agg's binary_logloss: 0.0171365 + 0.000198929\n",
      "[100]\tcv_agg's binary_logloss: 0.0162793 + 0.000202121\n",
      "[120]\tcv_agg's binary_logloss: 0.0158437 + 0.00021699\n",
      "[140]\tcv_agg's binary_logloss: 0.0156268 + 0.000208391\n",
      "[160]\tcv_agg's binary_logloss: 0.0154985 + 0.000232281\n",
      "[180]\tcv_agg's binary_logloss: 0.0154395 + 0.000249458\n",
      "[200]\tcv_agg's binary_logloss: 0.0154121 + 0.000244705\n",
      "[220]\tcv_agg's binary_logloss: 0.0153975 + 0.000251805\n",
      "[240]\tcv_agg's binary_logloss: 0.0153922 + 0.000257281\n",
      "[260]\tcv_agg's binary_logloss: 0.01538 + 0.000251256\n",
      "[280]\tcv_agg's binary_logloss: 0.0153969 + 0.00027378\n",
      "[300]\tcv_agg's binary_logloss: 0.0154232 + 0.000285013\n",
      "Starting cv for : 300\n",
      "[20]\tcv_agg's binary_logloss: 0.0912299 + 0.000200594\n",
      "[40]\tcv_agg's binary_logloss: 0.0307431 + 0.000258411\n",
      "[60]\tcv_agg's binary_logloss: 0.0202871 + 0.00019821\n",
      "[80]\tcv_agg's binary_logloss: 0.0171365 + 0.000198929\n",
      "[100]\tcv_agg's binary_logloss: 0.0162793 + 0.000202121\n",
      "[120]\tcv_agg's binary_logloss: 0.0158437 + 0.00021699\n",
      "[140]\tcv_agg's binary_logloss: 0.0156268 + 0.000208391\n",
      "[160]\tcv_agg's binary_logloss: 0.0154985 + 0.000232281\n",
      "[180]\tcv_agg's binary_logloss: 0.0154395 + 0.000249458\n",
      "[200]\tcv_agg's binary_logloss: 0.0154121 + 0.000244705\n",
      "[220]\tcv_agg's binary_logloss: 0.0153975 + 0.000251805\n",
      "[240]\tcv_agg's binary_logloss: 0.0153922 + 0.000257281\n",
      "[260]\tcv_agg's binary_logloss: 0.01538 + 0.000251256\n",
      "[280]\tcv_agg's binary_logloss: 0.0153969 + 0.00027378\n",
      "[300]\tcv_agg's binary_logloss: 0.0154232 + 0.000285013\n",
      "Starting cv for : 350\n",
      "[20]\tcv_agg's binary_logloss: 0.0912299 + 0.000200594\n",
      "[40]\tcv_agg's binary_logloss: 0.0307431 + 0.000258411\n",
      "[60]\tcv_agg's binary_logloss: 0.0202871 + 0.00019821\n",
      "[80]\tcv_agg's binary_logloss: 0.0171365 + 0.000198929\n",
      "[100]\tcv_agg's binary_logloss: 0.0162793 + 0.000202121\n",
      "[120]\tcv_agg's binary_logloss: 0.0158437 + 0.00021699\n",
      "[140]\tcv_agg's binary_logloss: 0.0156268 + 0.000208391\n",
      "[160]\tcv_agg's binary_logloss: 0.0154985 + 0.000232281\n",
      "[180]\tcv_agg's binary_logloss: 0.0154395 + 0.000249458\n",
      "[200]\tcv_agg's binary_logloss: 0.0154121 + 0.000244705\n",
      "[220]\tcv_agg's binary_logloss: 0.0153975 + 0.000251805\n",
      "[240]\tcv_agg's binary_logloss: 0.0153922 + 0.000257281\n",
      "[260]\tcv_agg's binary_logloss: 0.01538 + 0.000251256\n",
      "[280]\tcv_agg's binary_logloss: 0.0153969 + 0.00027378\n",
      "[300]\tcv_agg's binary_logloss: 0.0154232 + 0.000285013\n",
      "Starting cv for : 400\n",
      "[20]\tcv_agg's binary_logloss: 0.0912299 + 0.000200594\n",
      "[40]\tcv_agg's binary_logloss: 0.0307431 + 0.000258411\n",
      "[60]\tcv_agg's binary_logloss: 0.0202871 + 0.00019821\n",
      "[80]\tcv_agg's binary_logloss: 0.0171365 + 0.000198929\n",
      "[100]\tcv_agg's binary_logloss: 0.0162793 + 0.000202121\n",
      "[120]\tcv_agg's binary_logloss: 0.0158437 + 0.00021699\n",
      "[140]\tcv_agg's binary_logloss: 0.0156268 + 0.000208391\n",
      "[160]\tcv_agg's binary_logloss: 0.0154985 + 0.000232281\n",
      "[180]\tcv_agg's binary_logloss: 0.0154395 + 0.000249458\n",
      "[200]\tcv_agg's binary_logloss: 0.0154121 + 0.000244705\n",
      "[220]\tcv_agg's binary_logloss: 0.0153975 + 0.000251805\n",
      "[240]\tcv_agg's binary_logloss: 0.0153922 + 0.000257281\n",
      "[260]\tcv_agg's binary_logloss: 0.01538 + 0.000251256\n",
      "[280]\tcv_agg's binary_logloss: 0.0153969 + 0.00027378\n",
      "[300]\tcv_agg's binary_logloss: 0.0154232 + 0.000285013\n",
      "Starting cv for : 450\n",
      "[20]\tcv_agg's binary_logloss: 0.0912299 + 0.000200594\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e4ba4658e661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\\n# Imagine now that you want to optimize num_leaves and\\n# learning_rate, and also use early stopping:\\nbins = [i for i in range(200,501,50)]\\n\\n\\n# We will store the cross validation results in a simple list,\\n# with tuples in the form of (hyperparam dict, cv score):\\ncv_results = []\\n\\nfor max_bi in bins:\\n    print \"Starting cv for :\", max_bi\\n        \\n    lgb_params = {\\n    \\'learning_rate\\': 0.1,\\n        \\'max_depth\\': 8,\\n        \\'task\\': \\'train\\',\\n        \\'boosting_type\\': \\'gbdt\\',\\n        \\'objective\\': \\'binary\\',\\n        \\'feature_fraction\\': 0.75,\\n        \\'bagging_fraction\\': 0.75,\\n        \\'num_leaves\\':256,\\n        \\'min_data_in_leaf\\':900,\\n        \\'lambda_l1\\': 0.8,\\n        \\'lambda_l2\\':0.4,\\n        \\'max_bin\\':max_bi}\\n    validation_summary = lgb.cv(lgb_params,\\n                                                                 dtrain_lgb_full,\\n                                                                 num_boost_round=4000, # any high number will do\\n                                                                 nfold=5,\\n                                                                 metrics=[\"binary_logloss\"],\\n                                                                \\n                                                                 early_stopping_rounds=50, # Here it is\\n                                                                 verbose_eval=20)\\n    optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\\n        # Let\\'s just add the optimal number of trees (chosen by early stopping)\\n        # to the hyperparameter dictionary:\\n    lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\\n\\n       # And we append results to cv_results:\\n    cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    446\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    447\u001b[0m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mhandlerFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \"\"\"\n\u001b[1;32m   1643\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 1644\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/delavergne/anaconda3/envs/NLP/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   1899\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "bins = [i for i in range(100,251,50)]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for max_bi in bins:\n",
    "    print \"Starting cv for :\", max_bi\n",
    "        \n",
    "    lgb_params = {\n",
    "    'learning_rate': 0.1,\n",
    "        'max_depth': 8,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'num_leaves':256,\n",
    "        'min_data_in_leaf':900,\n",
    "        'lambda_l1': 0.8,\n",
    "        'lambda_l2':0.4,\n",
    "        'max_bin':max_bi}\n",
    "    validation_summary = lgb.cv(lgb_params,\n",
    "                                                                 dtrain_lgb_full,\n",
    "                                                                 num_boost_round=4000, # any high number will do\n",
    "                                                                 nfold=5,\n",
    "                                                                 metrics=[\"binary_logloss\"],\n",
    "                                                                \n",
    "                                                                 early_stopping_rounds=50, # Here it is\n",
    "                                                                 verbose_eval=20)\n",
    "    optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "        # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "        # to the hyperparameter dictionary:\n",
    "    lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "       # And we append results to cv_results:\n",
    "    cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'bagging_fraction': 0.75,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.75,\n",
       "   'lambda_l1': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_bin': 100,\n",
       "   'max_depth': 14,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 256,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 121,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.015839546633335075),\n",
       " ({'bagging_fraction': 0.75,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.75,\n",
       "   'lambda_l1': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_bin': 100,\n",
       "   'max_depth': 14,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 64,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 121,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.015666990180683637),\n",
       " ({'bagging_fraction': 0.75,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.75,\n",
       "   'lambda_l1': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_bin': 100,\n",
       "   'max_depth': 14,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 128,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 141,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.015480893774239089),\n",
       " ({'bagging_fraction': 0.75,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.75,\n",
       "   'lambda_l1': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_bin': 100,\n",
       "   'max_depth': 14,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'num_leaves': 256,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 110,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.015710831682326419)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2g\"></a>\n",
    "### Feature fraction tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cv for : 0.75\n",
      "[100]\tcv_agg's binary_logloss: 0.0669939 + 0.00108001\n",
      "[200]\tcv_agg's binary_logloss: 0.0617569 + 0.00117524\n",
      "[300]\tcv_agg's binary_logloss: 0.0598 + 0.00123877\n",
      "[400]\tcv_agg's binary_logloss: 0.0588969 + 0.00126617\n",
      "[500]\tcv_agg's binary_logloss: 0.0584237 + 0.0012595\n",
      "[600]\tcv_agg's binary_logloss: 0.0581457 + 0.00127014\n",
      "[700]\tcv_agg's binary_logloss: 0.0580075 + 0.00128115\n",
      "[800]\tcv_agg's binary_logloss: 0.0579343 + 0.00129584\n",
      "[900]\tcv_agg's binary_logloss: 0.0579044 + 0.00128929\n",
      "Starting cv for : 0.8\n",
      "[100]\tcv_agg's binary_logloss: 0.0670704 + 0.00108174\n",
      "[200]\tcv_agg's binary_logloss: 0.06172 + 0.00119799\n",
      "[300]\tcv_agg's binary_logloss: 0.0598015 + 0.00121759\n",
      "[400]\tcv_agg's binary_logloss: 0.0588911 + 0.00123391\n",
      "[500]\tcv_agg's binary_logloss: 0.0584094 + 0.00125453\n",
      "[600]\tcv_agg's binary_logloss: 0.0581549 + 0.00126165\n",
      "[700]\tcv_agg's binary_logloss: 0.0580025 + 0.0012601\n",
      "[800]\tcv_agg's binary_logloss: 0.0579299 + 0.00128427\n",
      "[900]\tcv_agg's binary_logloss: 0.057897 + 0.00128358\n",
      "Starting cv for : 0.85\n",
      "[100]\tcv_agg's binary_logloss: 0.0670737 + 0.00107202\n",
      "[200]\tcv_agg's binary_logloss: 0.0618044 + 0.00117284\n",
      "[300]\tcv_agg's binary_logloss: 0.0598553 + 0.00118807\n",
      "[400]\tcv_agg's binary_logloss: 0.0589234 + 0.00119987\n",
      "[500]\tcv_agg's binary_logloss: 0.0584243 + 0.00121463\n",
      "[600]\tcv_agg's binary_logloss: 0.0581636 + 0.00121004\n",
      "[700]\tcv_agg's binary_logloss: 0.0580196 + 0.00119799\n",
      "[800]\tcv_agg's binary_logloss: 0.0579459 + 0.00119812\n",
      "[900]\tcv_agg's binary_logloss: 0.0579185 + 0.00120191\n",
      "Starting cv for : 0.9\n",
      "[100]\tcv_agg's binary_logloss: 0.0670814 + 0.00110718\n",
      "[200]\tcv_agg's binary_logloss: 0.0617176 + 0.00123167\n",
      "[300]\tcv_agg's binary_logloss: 0.0598093 + 0.00126947\n",
      "[400]\tcv_agg's binary_logloss: 0.0589093 + 0.00129335\n",
      "[500]\tcv_agg's binary_logloss: 0.0584305 + 0.00130103\n",
      "[600]\tcv_agg's binary_logloss: 0.0581504 + 0.00131628\n",
      "[700]\tcv_agg's binary_logloss: 0.0580175 + 0.00131992\n",
      "[800]\tcv_agg's binary_logloss: 0.0579523 + 0.00132952\n",
      "[900]\tcv_agg's binary_logloss: 0.0579431 + 0.00131648\n",
      "Starting cv for : 0.95\n",
      "[100]\tcv_agg's binary_logloss: 0.0671024 + 0.00108235\n",
      "[200]\tcv_agg's binary_logloss: 0.0617435 + 0.00119848\n",
      "[300]\tcv_agg's binary_logloss: 0.0598407 + 0.00124526\n",
      "[400]\tcv_agg's binary_logloss: 0.0588975 + 0.00125832\n",
      "[500]\tcv_agg's binary_logloss: 0.0584163 + 0.00130718\n",
      "[600]\tcv_agg's binary_logloss: 0.0581417 + 0.00130162\n",
      "[700]\tcv_agg's binary_logloss: 0.0580102 + 0.00130237\n",
      "[800]\tcv_agg's binary_logloss: 0.0579473 + 0.00130209\n",
      "[900]\tcv_agg's binary_logloss: 0.057935 + 0.00130683\n",
      "Starting cv for : 1.0\n",
      "[100]\tcv_agg's binary_logloss: 0.0671315 + 0.00113486\n",
      "[200]\tcv_agg's binary_logloss: 0.061707 + 0.00123363\n",
      "[300]\tcv_agg's binary_logloss: 0.0598522 + 0.00125668\n",
      "[400]\tcv_agg's binary_logloss: 0.0589379 + 0.00128727\n",
      "[500]\tcv_agg's binary_logloss: 0.0584615 + 0.00128113\n",
      "[600]\tcv_agg's binary_logloss: 0.0582034 + 0.00128495\n",
      "[700]\tcv_agg's binary_logloss: 0.0580649 + 0.0012964\n",
      "[800]\tcv_agg's binary_logloss: 0.0579965 + 0.0013044\n",
      "[900]\tcv_agg's binary_logloss: 0.0579588 + 0.00129068\n",
      "CPU times: user 53min 22s, sys: 2min 14s, total: 55min 36s\n",
      "Wall time: 17min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain_lgb_full = lgb.Dataset(training_features, labels_array)\n",
    "# Imagine now that you want to optimize num_leaves and\n",
    "# learning_rate, and also use early stopping:\n",
    "feat_frac = [i/100.0 for i in range(75,101,5)]\n",
    "\n",
    "\n",
    "# We will store the cross validation results in a simple list,\n",
    "# with tuples in the form of (hyperparam dict, cv score):\n",
    "cv_results = []\n",
    "\n",
    "for frac in feat_frac:\n",
    "    print \"Starting cv for :\", frac\n",
    "        \n",
    "    lgb_params = {\n",
    "    'learning_rate': 0.07,\n",
    "        'max_depth': 5,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'feature_fraction': frac,\n",
    "        'num_leaves':30,\n",
    "        'min_data_in_leaf':600,\n",
    "        'lambda_l1': 0.7,\n",
    "        'lambda_l2':0.6}\n",
    "    validation_summary = lgb.cv(lgb_params,\n",
    "                                                                 dtrain_lgb_full,\n",
    "                                                                 num_boost_round=4000, # any high number will do\n",
    "                                                                 nfold=5,\n",
    "                                                                 metrics=[\"binary_logloss\"],\n",
    "                                                                \n",
    "                                                                 early_stopping_rounds=50, # Here it is\n",
    "                                                                 verbose_eval=100)\n",
    "    optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "        # Let's just add the optimal number of trees (chosen by early stopping)\n",
    "        # to the hyperparameter dictionary:\n",
    "    lgb_params[\"optimal_number_of_trees\"] = optimal_num_trees\n",
    "\n",
    "       # And we append results to cv_results:\n",
    "    cv_results.append((lgb_params, validation_summary[\"binary_logloss-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 1.0,\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 868,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057900598062077167),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.8,\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 887,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057892973805677386),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.85,\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 893,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.0579147386670293),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.9,\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 910,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057934307321364807),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 0.95,\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 858,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057933455823817238),\n",
       " ({'boosting_type': 'gbdt',\n",
       "   'feature_fraction': 1.0,\n",
       "   'lambda_l1': 0.7,\n",
       "   'lambda_l2': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 5,\n",
       "   'metric': ['binary_logloss'],\n",
       "   'min_data_in_leaf': 600,\n",
       "   'num_leaves': 30,\n",
       "   'objective': 'binary',\n",
       "   'optimal_number_of_trees': 892,\n",
       "   'task': 'train',\n",
       "   'verbose': 1},\n",
       "  0.057953036288266799)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Defining the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'learning_rate': 0.07,\n",
    "        'max_depth': 5,\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'feature_fraction': 0.8,\n",
    "        'num_leaves':30,\n",
    "        'min_data_in_leaf':600,\n",
    "        'lambda_l1': 0.7,\n",
    "        'lambda_l2':0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of the optimal number of boosting rounds with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's binary_logloss: 0.384789 + 9.68792e-05\n",
      "[100]\tcv_agg's binary_logloss: 0.232227 + 0.000163719\n",
      "[150]\tcv_agg's binary_logloss: 0.145945 + 0.000184383\n",
      "[200]\tcv_agg's binary_logloss: 0.0967113 + 0.000195211\n",
      "[250]\tcv_agg's binary_logloss: 0.0674862 + 0.000221474\n",
      "[300]\tcv_agg's binary_logloss: 0.0503866 + 0.000230637\n",
      "[350]\tcv_agg's binary_logloss: 0.0389355 + 0.00023761\n",
      "[400]\tcv_agg's binary_logloss: 0.0314532 + 0.000238527\n",
      "[450]\tcv_agg's binary_logloss: 0.0265072 + 0.000221055\n",
      "[500]\tcv_agg's binary_logloss: 0.0235413 + 0.000210612\n",
      "[550]\tcv_agg's binary_logloss: 0.0215375 + 0.000189209\n",
      "[600]\tcv_agg's binary_logloss: 0.019959 + 0.000174961\n",
      "[650]\tcv_agg's binary_logloss: 0.0188688 + 0.000165177\n",
      "[700]\tcv_agg's binary_logloss: 0.0181695 + 0.000159844\n",
      "[750]\tcv_agg's binary_logloss: 0.017615 + 0.000163786\n",
      "[800]\tcv_agg's binary_logloss: 0.0171738 + 0.000166393\n",
      "[850]\tcv_agg's binary_logloss: 0.016825 + 0.000166354\n",
      "[900]\tcv_agg's binary_logloss: 0.0165705 + 0.000166443\n",
      "[950]\tcv_agg's binary_logloss: 0.0163726 + 0.000166508\n",
      "[1000]\tcv_agg's binary_logloss: 0.0162104 + 0.000170607\n",
      "[1050]\tcv_agg's binary_logloss: 0.0160849 + 0.000171907\n",
      "[1100]\tcv_agg's binary_logloss: 0.0159733 + 0.000175608\n",
      "[1150]\tcv_agg's binary_logloss: 0.0158691 + 0.000180735\n",
      "[1200]\tcv_agg's binary_logloss: 0.0157974 + 0.000179764\n",
      "[1250]\tcv_agg's binary_logloss: 0.0157233 + 0.000182329\n",
      "[1300]\tcv_agg's binary_logloss: 0.0156606 + 0.000186696\n",
      "[1350]\tcv_agg's binary_logloss: 0.0156133 + 0.000190029\n",
      "[1400]\tcv_agg's binary_logloss: 0.0155662 + 0.000194125\n",
      "[1450]\tcv_agg's binary_logloss: 0.0155261 + 0.000194237\n",
      "[1500]\tcv_agg's binary_logloss: 0.0154923 + 0.000193283\n",
      "[1550]\tcv_agg's binary_logloss: 0.0154591 + 0.000194244\n",
      "[1600]\tcv_agg's binary_logloss: 0.0154348 + 0.000193924\n",
      "[1650]\tcv_agg's binary_logloss: 0.0154118 + 0.000194263\n",
      "[1700]\tcv_agg's binary_logloss: 0.0153899 + 0.000193079\n",
      "[1750]\tcv_agg's binary_logloss: 0.0153722 + 0.00019587\n",
      "[1800]\tcv_agg's binary_logloss: 0.0153553 + 0.000200136\n",
      "[1850]\tcv_agg's binary_logloss: 0.0153392 + 0.000205968\n",
      "[1900]\tcv_agg's binary_logloss: 0.0153257 + 0.000211978\n",
      "[1950]\tcv_agg's binary_logloss: 0.0153124 + 0.000214197\n",
      "[2000]\tcv_agg's binary_logloss: 0.0153047 + 0.000216014\n",
      "[2050]\tcv_agg's binary_logloss: 0.0152953 + 0.000214241\n",
      "[2100]\tcv_agg's binary_logloss: 0.0152871 + 0.000216602\n",
      "[2150]\tcv_agg's binary_logloss: 0.0152805 + 0.000218397\n",
      "[2200]\tcv_agg's binary_logloss: 0.0152743 + 0.000222006\n",
      "[2250]\tcv_agg's binary_logloss: 0.0152711 + 0.000226977\n",
      "[2300]\tcv_agg's binary_logloss: 0.0152691 + 0.000231385\n",
      "[2350]\tcv_agg's binary_logloss: 0.0152645 + 0.000231456\n",
      "[2400]\tcv_agg's binary_logloss: 0.0152609 + 0.000235557\n",
      "[2450]\tcv_agg's binary_logloss: 0.0152542 + 0.000240242\n",
      "[2500]\tcv_agg's binary_logloss: 0.0152507 + 0.000240179\n",
      "[2550]\tcv_agg's binary_logloss: 0.0152483 + 0.000243063\n",
      "[2600]\tcv_agg's binary_logloss: 0.0152495 + 0.000244473\n",
      "2552\n"
     ]
    }
   ],
   "source": [
    "validation_summary = lgb.cv(lgb_params,\n",
    "                                                                 dtrain_lgb_full,\n",
    "                                                                 num_boost_round=10000, # any high number will do\n",
    "                                                                 nfold=5,\n",
    "                                                                 metrics=[\"binary_logloss\"],\n",
    "                                                                \n",
    "                                                                 early_stopping_rounds=50, # Here it is\n",
    "                                                                 verbose_eval=50)\n",
    "optimal_num_trees = len(validation_summary[\"binary_logloss-mean\"])\n",
    "print optimal_num_trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
